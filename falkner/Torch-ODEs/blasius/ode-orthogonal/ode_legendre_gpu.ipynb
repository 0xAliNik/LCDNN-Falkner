{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt install swig\n",
        "!pip install orthnet"
      ],
      "metadata": {
        "id": "rUikrwurWg6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d962edab-fbe0-46b1-decb-866bc5e55f47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 1,100 kB of archives.\n",
            "After this operation, 5,822 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 1,100 kB in 2s (563 kB/s)\n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 155203 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting orthnet\n",
            "  Downloading orthnet-0.4.0.tar.gz (206 kB)\n",
            "\u001b[K     |████████████████████████████████| 206 kB 4.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: orthnet\n",
            "  Building wheel for orthnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for orthnet: filename=orthnet-0.4.0-cp37-cp37m-linux_x86_64.whl size=157650 sha256=ca5231241820184e64bf6bfcff1a9407076aeeea14bffb6bfe90a077bdd62d57\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/8c/c1/1344cc2d551c4f7c3831d216b39d50ccb07f4b3f3a5eb79c96\n",
            "Successfully built orthnet\n",
            "Installing collected packages: orthnet\n",
            "Successfully installed orthnet-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uGSiDN4bVyDe"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch import randn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch import nn\n",
        "\n",
        "import random, os\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import pandas as pd\n",
        "\n",
        "from orthnet import Legendre, Chebyshev\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda0 = torch.device('cuda:0')\n",
        "print(torch.cuda.device_count(), torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh9WdW5ofFuc",
        "outputId": "6bce0429-d369-4827-8d04-301cb8e8538b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.init()"
      ],
      "metadata": {
        "id": "Lb6thc4NhmKM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pFyCR5IXVyDq"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "w8taawEZVyDs"
      },
      "outputs": [],
      "source": [
        "class LegendreActivation(nn.Module):\n",
        "    def __init__(self,degree):\n",
        "        super().__init__()\n",
        "        self.degree = degree\n",
        "        self.data = None\n",
        "        \n",
        "        self.D = torch.zeros((degree , degree )) \n",
        "        for i in range(degree):\n",
        "          for j in range(0 , i):\n",
        "            if (i + j) % 2 == 1:\n",
        "              self.D[i, j] = 2 * (j + 1) - 1\n",
        "    \n",
        "    def forward(self, X):              \n",
        "      data = Legendre(X, self.degree).tensor\n",
        "      self.data = data\n",
        "      return data\n",
        "\n",
        "    def backward(self,):\n",
        "      return (self.D @ (self.data).T).T\n",
        "\n",
        "\n",
        "class LegendreBlock(nn.Module):\n",
        "    def __init__(self, n_input, degree):        \n",
        "        super().__init__()\n",
        "        self.degree = degree - 1\n",
        "        self.n_input = n_input\n",
        "        self.linear = nn.Linear(self.n_input, 1).double()\n",
        "        self.tanh = nn.Tanh().double()\n",
        "        self.Legendre = LegendreActivation(self.degree)\n",
        "\n",
        "    def forward(self, X):      \n",
        "      X = self.tanh(self.linear(X))      \n",
        "      data = self.Legendre(X)\n",
        "      return data\n",
        "\n",
        "class ChebyshevActivation(nn.Module):\n",
        "    def __init__(self,degree):\n",
        "        super().__init__()\n",
        "        self.degree = degree\n",
        "        self.data = None\n",
        "        \n",
        "        self.D = torch.zeros((degree , degree )) \n",
        "        for i in range(degree):\n",
        "          for j in range(0 ,i):\n",
        "            if (i+j) % 2 == 1:\n",
        "              self.D[i, j] = 2 * i\n",
        "              if j == 0:\n",
        "                self.D[i, j] = self.D[i, j]/2.0\n",
        "    def forward(self, X):              \n",
        "      data = Chebyshev(X, self.degree).tensor\n",
        "      self.data = data\n",
        "      return data\n",
        "\n",
        "    def backward(self,):\n",
        "      return (self.D @ (self.data).T).T\n",
        "\n",
        "class ChebyshevBlock(nn.Module):\n",
        "    def __init__(self, n_input, degree):        \n",
        "        super().__init__()\n",
        "        self.degree = degree - 1\n",
        "        \n",
        "        self.n_input = n_input\n",
        "        self.linear = nn.Linear(self.n_input, 1).double()\n",
        "        self.tanh = nn.Tanh().double()\n",
        "        self.Chebyshev = ChebyshevActivation(self.degree)\n",
        "\n",
        "\n",
        "    def forward(self, X):      \n",
        "      X = self.tanh(self.linear(X))      \n",
        "      data = self.Chebyshev(X)\n",
        "      \n",
        "      return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "HSCVIWphVyDw"
      },
      "outputs": [],
      "source": [
        "def dy_dx(y, x):\n",
        "  return torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
        "\n",
        "def d2y_dx2(y, x):\n",
        "  return dy_dx(dy_dx(y,x), x)\n",
        "\n",
        "def d3y_dx3(y, x):\n",
        "  return dy_dx(d2y_dx2(y,x), x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TfdH0fFtVyDy"
      },
      "outputs": [],
      "source": [
        "domain = [0, 1]\n",
        "n_discretization = 1000 * domain[1] - domain[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uItLWMf5VyDz"
      },
      "outputs": [],
      "source": [
        "n_input = 1\n",
        "n_output = 1\n",
        "eps = 1e-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7RRGAEaeVyD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed693b79-1c08-4c34-cefc-096d55a0613d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000e-10],\n",
            "        [1.0010e-03],\n",
            "        [2.0020e-03],\n",
            "        [3.0030e-03],\n",
            "        [4.0040e-03],\n",
            "        [5.0050e-03],\n",
            "        [6.0060e-03],\n",
            "        [7.0070e-03],\n",
            "        [8.0080e-03],\n",
            "        [9.0090e-03],\n",
            "        [1.0010e-02],\n",
            "        [1.1011e-02],\n",
            "        [1.2012e-02],\n",
            "        [1.3013e-02],\n",
            "        [1.4014e-02],\n",
            "        [1.5015e-02],\n",
            "        [1.6016e-02],\n",
            "        [1.7017e-02],\n",
            "        [1.8018e-02],\n",
            "        [1.9019e-02],\n",
            "        [2.0020e-02],\n",
            "        [2.1021e-02],\n",
            "        [2.2022e-02],\n",
            "        [2.3023e-02],\n",
            "        [2.4024e-02],\n",
            "        [2.5025e-02],\n",
            "        [2.6026e-02],\n",
            "        [2.7027e-02],\n",
            "        [2.8028e-02],\n",
            "        [2.9029e-02],\n",
            "        [3.0030e-02],\n",
            "        [3.1031e-02],\n",
            "        [3.2032e-02],\n",
            "        [3.3033e-02],\n",
            "        [3.4034e-02],\n",
            "        [3.5035e-02],\n",
            "        [3.6036e-02],\n",
            "        [3.7037e-02],\n",
            "        [3.8038e-02],\n",
            "        [3.9039e-02],\n",
            "        [4.0040e-02],\n",
            "        [4.1041e-02],\n",
            "        [4.2042e-02],\n",
            "        [4.3043e-02],\n",
            "        [4.4044e-02],\n",
            "        [4.5045e-02],\n",
            "        [4.6046e-02],\n",
            "        [4.7047e-02],\n",
            "        [4.8048e-02],\n",
            "        [4.9049e-02],\n",
            "        [5.0050e-02],\n",
            "        [5.1051e-02],\n",
            "        [5.2052e-02],\n",
            "        [5.3053e-02],\n",
            "        [5.4054e-02],\n",
            "        [5.5055e-02],\n",
            "        [5.6056e-02],\n",
            "        [5.7057e-02],\n",
            "        [5.8058e-02],\n",
            "        [5.9059e-02],\n",
            "        [6.0060e-02],\n",
            "        [6.1061e-02],\n",
            "        [6.2062e-02],\n",
            "        [6.3063e-02],\n",
            "        [6.4064e-02],\n",
            "        [6.5065e-02],\n",
            "        [6.6066e-02],\n",
            "        [6.7067e-02],\n",
            "        [6.8068e-02],\n",
            "        [6.9069e-02],\n",
            "        [7.0070e-02],\n",
            "        [7.1071e-02],\n",
            "        [7.2072e-02],\n",
            "        [7.3073e-02],\n",
            "        [7.4074e-02],\n",
            "        [7.5075e-02],\n",
            "        [7.6076e-02],\n",
            "        [7.7077e-02],\n",
            "        [7.8078e-02],\n",
            "        [7.9079e-02],\n",
            "        [8.0080e-02],\n",
            "        [8.1081e-02],\n",
            "        [8.2082e-02],\n",
            "        [8.3083e-02],\n",
            "        [8.4084e-02],\n",
            "        [8.5085e-02],\n",
            "        [8.6086e-02],\n",
            "        [8.7087e-02],\n",
            "        [8.8088e-02],\n",
            "        [8.9089e-02],\n",
            "        [9.0090e-02],\n",
            "        [9.1091e-02],\n",
            "        [9.2092e-02],\n",
            "        [9.3093e-02],\n",
            "        [9.4094e-02],\n",
            "        [9.5095e-02],\n",
            "        [9.6096e-02],\n",
            "        [9.7097e-02],\n",
            "        [9.8098e-02],\n",
            "        [9.9099e-02],\n",
            "        [1.0010e-01],\n",
            "        [1.0110e-01],\n",
            "        [1.0210e-01],\n",
            "        [1.0310e-01],\n",
            "        [1.0410e-01],\n",
            "        [1.0511e-01],\n",
            "        [1.0611e-01],\n",
            "        [1.0711e-01],\n",
            "        [1.0811e-01],\n",
            "        [1.0911e-01],\n",
            "        [1.1011e-01],\n",
            "        [1.1111e-01],\n",
            "        [1.1211e-01],\n",
            "        [1.1311e-01],\n",
            "        [1.1411e-01],\n",
            "        [1.1512e-01],\n",
            "        [1.1612e-01],\n",
            "        [1.1712e-01],\n",
            "        [1.1812e-01],\n",
            "        [1.1912e-01],\n",
            "        [1.2012e-01],\n",
            "        [1.2112e-01],\n",
            "        [1.2212e-01],\n",
            "        [1.2312e-01],\n",
            "        [1.2412e-01],\n",
            "        [1.2513e-01],\n",
            "        [1.2613e-01],\n",
            "        [1.2713e-01],\n",
            "        [1.2813e-01],\n",
            "        [1.2913e-01],\n",
            "        [1.3013e-01],\n",
            "        [1.3113e-01],\n",
            "        [1.3213e-01],\n",
            "        [1.3313e-01],\n",
            "        [1.3413e-01],\n",
            "        [1.3514e-01],\n",
            "        [1.3614e-01],\n",
            "        [1.3714e-01],\n",
            "        [1.3814e-01],\n",
            "        [1.3914e-01],\n",
            "        [1.4014e-01],\n",
            "        [1.4114e-01],\n",
            "        [1.4214e-01],\n",
            "        [1.4314e-01],\n",
            "        [1.4414e-01],\n",
            "        [1.4515e-01],\n",
            "        [1.4615e-01],\n",
            "        [1.4715e-01],\n",
            "        [1.4815e-01],\n",
            "        [1.4915e-01],\n",
            "        [1.5015e-01],\n",
            "        [1.5115e-01],\n",
            "        [1.5215e-01],\n",
            "        [1.5315e-01],\n",
            "        [1.5415e-01],\n",
            "        [1.5516e-01],\n",
            "        [1.5616e-01],\n",
            "        [1.5716e-01],\n",
            "        [1.5816e-01],\n",
            "        [1.5916e-01],\n",
            "        [1.6016e-01],\n",
            "        [1.6116e-01],\n",
            "        [1.6216e-01],\n",
            "        [1.6316e-01],\n",
            "        [1.6416e-01],\n",
            "        [1.6517e-01],\n",
            "        [1.6617e-01],\n",
            "        [1.6717e-01],\n",
            "        [1.6817e-01],\n",
            "        [1.6917e-01],\n",
            "        [1.7017e-01],\n",
            "        [1.7117e-01],\n",
            "        [1.7217e-01],\n",
            "        [1.7317e-01],\n",
            "        [1.7417e-01],\n",
            "        [1.7518e-01],\n",
            "        [1.7618e-01],\n",
            "        [1.7718e-01],\n",
            "        [1.7818e-01],\n",
            "        [1.7918e-01],\n",
            "        [1.8018e-01],\n",
            "        [1.8118e-01],\n",
            "        [1.8218e-01],\n",
            "        [1.8318e-01],\n",
            "        [1.8418e-01],\n",
            "        [1.8519e-01],\n",
            "        [1.8619e-01],\n",
            "        [1.8719e-01],\n",
            "        [1.8819e-01],\n",
            "        [1.8919e-01],\n",
            "        [1.9019e-01],\n",
            "        [1.9119e-01],\n",
            "        [1.9219e-01],\n",
            "        [1.9319e-01],\n",
            "        [1.9419e-01],\n",
            "        [1.9520e-01],\n",
            "        [1.9620e-01],\n",
            "        [1.9720e-01],\n",
            "        [1.9820e-01],\n",
            "        [1.9920e-01],\n",
            "        [2.0020e-01],\n",
            "        [2.0120e-01],\n",
            "        [2.0220e-01],\n",
            "        [2.0320e-01],\n",
            "        [2.0420e-01],\n",
            "        [2.0521e-01],\n",
            "        [2.0621e-01],\n",
            "        [2.0721e-01],\n",
            "        [2.0821e-01],\n",
            "        [2.0921e-01],\n",
            "        [2.1021e-01],\n",
            "        [2.1121e-01],\n",
            "        [2.1221e-01],\n",
            "        [2.1321e-01],\n",
            "        [2.1421e-01],\n",
            "        [2.1522e-01],\n",
            "        [2.1622e-01],\n",
            "        [2.1722e-01],\n",
            "        [2.1822e-01],\n",
            "        [2.1922e-01],\n",
            "        [2.2022e-01],\n",
            "        [2.2122e-01],\n",
            "        [2.2222e-01],\n",
            "        [2.2322e-01],\n",
            "        [2.2422e-01],\n",
            "        [2.2523e-01],\n",
            "        [2.2623e-01],\n",
            "        [2.2723e-01],\n",
            "        [2.2823e-01],\n",
            "        [2.2923e-01],\n",
            "        [2.3023e-01],\n",
            "        [2.3123e-01],\n",
            "        [2.3223e-01],\n",
            "        [2.3323e-01],\n",
            "        [2.3423e-01],\n",
            "        [2.3524e-01],\n",
            "        [2.3624e-01],\n",
            "        [2.3724e-01],\n",
            "        [2.3824e-01],\n",
            "        [2.3924e-01],\n",
            "        [2.4024e-01],\n",
            "        [2.4124e-01],\n",
            "        [2.4224e-01],\n",
            "        [2.4324e-01],\n",
            "        [2.4424e-01],\n",
            "        [2.4525e-01],\n",
            "        [2.4625e-01],\n",
            "        [2.4725e-01],\n",
            "        [2.4825e-01],\n",
            "        [2.4925e-01],\n",
            "        [2.5025e-01],\n",
            "        [2.5125e-01],\n",
            "        [2.5225e-01],\n",
            "        [2.5325e-01],\n",
            "        [2.5425e-01],\n",
            "        [2.5526e-01],\n",
            "        [2.5626e-01],\n",
            "        [2.5726e-01],\n",
            "        [2.5826e-01],\n",
            "        [2.5926e-01],\n",
            "        [2.6026e-01],\n",
            "        [2.6126e-01],\n",
            "        [2.6226e-01],\n",
            "        [2.6326e-01],\n",
            "        [2.6426e-01],\n",
            "        [2.6527e-01],\n",
            "        [2.6627e-01],\n",
            "        [2.6727e-01],\n",
            "        [2.6827e-01],\n",
            "        [2.6927e-01],\n",
            "        [2.7027e-01],\n",
            "        [2.7127e-01],\n",
            "        [2.7227e-01],\n",
            "        [2.7327e-01],\n",
            "        [2.7427e-01],\n",
            "        [2.7528e-01],\n",
            "        [2.7628e-01],\n",
            "        [2.7728e-01],\n",
            "        [2.7828e-01],\n",
            "        [2.7928e-01],\n",
            "        [2.8028e-01],\n",
            "        [2.8128e-01],\n",
            "        [2.8228e-01],\n",
            "        [2.8328e-01],\n",
            "        [2.8428e-01],\n",
            "        [2.8529e-01],\n",
            "        [2.8629e-01],\n",
            "        [2.8729e-01],\n",
            "        [2.8829e-01],\n",
            "        [2.8929e-01],\n",
            "        [2.9029e-01],\n",
            "        [2.9129e-01],\n",
            "        [2.9229e-01],\n",
            "        [2.9329e-01],\n",
            "        [2.9429e-01],\n",
            "        [2.9530e-01],\n",
            "        [2.9630e-01],\n",
            "        [2.9730e-01],\n",
            "        [2.9830e-01],\n",
            "        [2.9930e-01],\n",
            "        [3.0030e-01],\n",
            "        [3.0130e-01],\n",
            "        [3.0230e-01],\n",
            "        [3.0330e-01],\n",
            "        [3.0430e-01],\n",
            "        [3.0531e-01],\n",
            "        [3.0631e-01],\n",
            "        [3.0731e-01],\n",
            "        [3.0831e-01],\n",
            "        [3.0931e-01],\n",
            "        [3.1031e-01],\n",
            "        [3.1131e-01],\n",
            "        [3.1231e-01],\n",
            "        [3.1331e-01],\n",
            "        [3.1431e-01],\n",
            "        [3.1532e-01],\n",
            "        [3.1632e-01],\n",
            "        [3.1732e-01],\n",
            "        [3.1832e-01],\n",
            "        [3.1932e-01],\n",
            "        [3.2032e-01],\n",
            "        [3.2132e-01],\n",
            "        [3.2232e-01],\n",
            "        [3.2332e-01],\n",
            "        [3.2432e-01],\n",
            "        [3.2533e-01],\n",
            "        [3.2633e-01],\n",
            "        [3.2733e-01],\n",
            "        [3.2833e-01],\n",
            "        [3.2933e-01],\n",
            "        [3.3033e-01],\n",
            "        [3.3133e-01],\n",
            "        [3.3233e-01],\n",
            "        [3.3333e-01],\n",
            "        [3.3433e-01],\n",
            "        [3.3534e-01],\n",
            "        [3.3634e-01],\n",
            "        [3.3734e-01],\n",
            "        [3.3834e-01],\n",
            "        [3.3934e-01],\n",
            "        [3.4034e-01],\n",
            "        [3.4134e-01],\n",
            "        [3.4234e-01],\n",
            "        [3.4334e-01],\n",
            "        [3.4434e-01],\n",
            "        [3.4535e-01],\n",
            "        [3.4635e-01],\n",
            "        [3.4735e-01],\n",
            "        [3.4835e-01],\n",
            "        [3.4935e-01],\n",
            "        [3.5035e-01],\n",
            "        [3.5135e-01],\n",
            "        [3.5235e-01],\n",
            "        [3.5335e-01],\n",
            "        [3.5435e-01],\n",
            "        [3.5536e-01],\n",
            "        [3.5636e-01],\n",
            "        [3.5736e-01],\n",
            "        [3.5836e-01],\n",
            "        [3.5936e-01],\n",
            "        [3.6036e-01],\n",
            "        [3.6136e-01],\n",
            "        [3.6236e-01],\n",
            "        [3.6336e-01],\n",
            "        [3.6436e-01],\n",
            "        [3.6537e-01],\n",
            "        [3.6637e-01],\n",
            "        [3.6737e-01],\n",
            "        [3.6837e-01],\n",
            "        [3.6937e-01],\n",
            "        [3.7037e-01],\n",
            "        [3.7137e-01],\n",
            "        [3.7237e-01],\n",
            "        [3.7337e-01],\n",
            "        [3.7437e-01],\n",
            "        [3.7538e-01],\n",
            "        [3.7638e-01],\n",
            "        [3.7738e-01],\n",
            "        [3.7838e-01],\n",
            "        [3.7938e-01],\n",
            "        [3.8038e-01],\n",
            "        [3.8138e-01],\n",
            "        [3.8238e-01],\n",
            "        [3.8338e-01],\n",
            "        [3.8438e-01],\n",
            "        [3.8539e-01],\n",
            "        [3.8639e-01],\n",
            "        [3.8739e-01],\n",
            "        [3.8839e-01],\n",
            "        [3.8939e-01],\n",
            "        [3.9039e-01],\n",
            "        [3.9139e-01],\n",
            "        [3.9239e-01],\n",
            "        [3.9339e-01],\n",
            "        [3.9439e-01],\n",
            "        [3.9540e-01],\n",
            "        [3.9640e-01],\n",
            "        [3.9740e-01],\n",
            "        [3.9840e-01],\n",
            "        [3.9940e-01],\n",
            "        [4.0040e-01],\n",
            "        [4.0140e-01],\n",
            "        [4.0240e-01],\n",
            "        [4.0340e-01],\n",
            "        [4.0440e-01],\n",
            "        [4.0541e-01],\n",
            "        [4.0641e-01],\n",
            "        [4.0741e-01],\n",
            "        [4.0841e-01],\n",
            "        [4.0941e-01],\n",
            "        [4.1041e-01],\n",
            "        [4.1141e-01],\n",
            "        [4.1241e-01],\n",
            "        [4.1341e-01],\n",
            "        [4.1441e-01],\n",
            "        [4.1542e-01],\n",
            "        [4.1642e-01],\n",
            "        [4.1742e-01],\n",
            "        [4.1842e-01],\n",
            "        [4.1942e-01],\n",
            "        [4.2042e-01],\n",
            "        [4.2142e-01],\n",
            "        [4.2242e-01],\n",
            "        [4.2342e-01],\n",
            "        [4.2442e-01],\n",
            "        [4.2543e-01],\n",
            "        [4.2643e-01],\n",
            "        [4.2743e-01],\n",
            "        [4.2843e-01],\n",
            "        [4.2943e-01],\n",
            "        [4.3043e-01],\n",
            "        [4.3143e-01],\n",
            "        [4.3243e-01],\n",
            "        [4.3343e-01],\n",
            "        [4.3443e-01],\n",
            "        [4.3544e-01],\n",
            "        [4.3644e-01],\n",
            "        [4.3744e-01],\n",
            "        [4.3844e-01],\n",
            "        [4.3944e-01],\n",
            "        [4.4044e-01],\n",
            "        [4.4144e-01],\n",
            "        [4.4244e-01],\n",
            "        [4.4344e-01],\n",
            "        [4.4444e-01],\n",
            "        [4.4545e-01],\n",
            "        [4.4645e-01],\n",
            "        [4.4745e-01],\n",
            "        [4.4845e-01],\n",
            "        [4.4945e-01],\n",
            "        [4.5045e-01],\n",
            "        [4.5145e-01],\n",
            "        [4.5245e-01],\n",
            "        [4.5345e-01],\n",
            "        [4.5445e-01],\n",
            "        [4.5546e-01],\n",
            "        [4.5646e-01],\n",
            "        [4.5746e-01],\n",
            "        [4.5846e-01],\n",
            "        [4.5946e-01],\n",
            "        [4.6046e-01],\n",
            "        [4.6146e-01],\n",
            "        [4.6246e-01],\n",
            "        [4.6346e-01],\n",
            "        [4.6446e-01],\n",
            "        [4.6547e-01],\n",
            "        [4.6647e-01],\n",
            "        [4.6747e-01],\n",
            "        [4.6847e-01],\n",
            "        [4.6947e-01],\n",
            "        [4.7047e-01],\n",
            "        [4.7147e-01],\n",
            "        [4.7247e-01],\n",
            "        [4.7347e-01],\n",
            "        [4.7447e-01],\n",
            "        [4.7548e-01],\n",
            "        [4.7648e-01],\n",
            "        [4.7748e-01],\n",
            "        [4.7848e-01],\n",
            "        [4.7948e-01],\n",
            "        [4.8048e-01],\n",
            "        [4.8148e-01],\n",
            "        [4.8248e-01],\n",
            "        [4.8348e-01],\n",
            "        [4.8448e-01],\n",
            "        [4.8549e-01],\n",
            "        [4.8649e-01],\n",
            "        [4.8749e-01],\n",
            "        [4.8849e-01],\n",
            "        [4.8949e-01],\n",
            "        [4.9049e-01],\n",
            "        [4.9149e-01],\n",
            "        [4.9249e-01],\n",
            "        [4.9349e-01],\n",
            "        [4.9449e-01],\n",
            "        [4.9550e-01],\n",
            "        [4.9650e-01],\n",
            "        [4.9750e-01],\n",
            "        [4.9850e-01],\n",
            "        [4.9950e-01],\n",
            "        [5.0050e-01],\n",
            "        [5.0150e-01],\n",
            "        [5.0250e-01],\n",
            "        [5.0350e-01],\n",
            "        [5.0450e-01],\n",
            "        [5.0551e-01],\n",
            "        [5.0651e-01],\n",
            "        [5.0751e-01],\n",
            "        [5.0851e-01],\n",
            "        [5.0951e-01],\n",
            "        [5.1051e-01],\n",
            "        [5.1151e-01],\n",
            "        [5.1251e-01],\n",
            "        [5.1351e-01],\n",
            "        [5.1451e-01],\n",
            "        [5.1552e-01],\n",
            "        [5.1652e-01],\n",
            "        [5.1752e-01],\n",
            "        [5.1852e-01],\n",
            "        [5.1952e-01],\n",
            "        [5.2052e-01],\n",
            "        [5.2152e-01],\n",
            "        [5.2252e-01],\n",
            "        [5.2352e-01],\n",
            "        [5.2452e-01],\n",
            "        [5.2553e-01],\n",
            "        [5.2653e-01],\n",
            "        [5.2753e-01],\n",
            "        [5.2853e-01],\n",
            "        [5.2953e-01],\n",
            "        [5.3053e-01],\n",
            "        [5.3153e-01],\n",
            "        [5.3253e-01],\n",
            "        [5.3353e-01],\n",
            "        [5.3453e-01],\n",
            "        [5.3554e-01],\n",
            "        [5.3654e-01],\n",
            "        [5.3754e-01],\n",
            "        [5.3854e-01],\n",
            "        [5.3954e-01],\n",
            "        [5.4054e-01],\n",
            "        [5.4154e-01],\n",
            "        [5.4254e-01],\n",
            "        [5.4354e-01],\n",
            "        [5.4454e-01],\n",
            "        [5.4555e-01],\n",
            "        [5.4655e-01],\n",
            "        [5.4755e-01],\n",
            "        [5.4855e-01],\n",
            "        [5.4955e-01],\n",
            "        [5.5055e-01],\n",
            "        [5.5155e-01],\n",
            "        [5.5255e-01],\n",
            "        [5.5355e-01],\n",
            "        [5.5455e-01],\n",
            "        [5.5556e-01],\n",
            "        [5.5656e-01],\n",
            "        [5.5756e-01],\n",
            "        [5.5856e-01],\n",
            "        [5.5956e-01],\n",
            "        [5.6056e-01],\n",
            "        [5.6156e-01],\n",
            "        [5.6256e-01],\n",
            "        [5.6356e-01],\n",
            "        [5.6456e-01],\n",
            "        [5.6557e-01],\n",
            "        [5.6657e-01],\n",
            "        [5.6757e-01],\n",
            "        [5.6857e-01],\n",
            "        [5.6957e-01],\n",
            "        [5.7057e-01],\n",
            "        [5.7157e-01],\n",
            "        [5.7257e-01],\n",
            "        [5.7357e-01],\n",
            "        [5.7457e-01],\n",
            "        [5.7558e-01],\n",
            "        [5.7658e-01],\n",
            "        [5.7758e-01],\n",
            "        [5.7858e-01],\n",
            "        [5.7958e-01],\n",
            "        [5.8058e-01],\n",
            "        [5.8158e-01],\n",
            "        [5.8258e-01],\n",
            "        [5.8358e-01],\n",
            "        [5.8458e-01],\n",
            "        [5.8559e-01],\n",
            "        [5.8659e-01],\n",
            "        [5.8759e-01],\n",
            "        [5.8859e-01],\n",
            "        [5.8959e-01],\n",
            "        [5.9059e-01],\n",
            "        [5.9159e-01],\n",
            "        [5.9259e-01],\n",
            "        [5.9359e-01],\n",
            "        [5.9459e-01],\n",
            "        [5.9560e-01],\n",
            "        [5.9660e-01],\n",
            "        [5.9760e-01],\n",
            "        [5.9860e-01],\n",
            "        [5.9960e-01],\n",
            "        [6.0060e-01],\n",
            "        [6.0160e-01],\n",
            "        [6.0260e-01],\n",
            "        [6.0360e-01],\n",
            "        [6.0460e-01],\n",
            "        [6.0561e-01],\n",
            "        [6.0661e-01],\n",
            "        [6.0761e-01],\n",
            "        [6.0861e-01],\n",
            "        [6.0961e-01],\n",
            "        [6.1061e-01],\n",
            "        [6.1161e-01],\n",
            "        [6.1261e-01],\n",
            "        [6.1361e-01],\n",
            "        [6.1461e-01],\n",
            "        [6.1562e-01],\n",
            "        [6.1662e-01],\n",
            "        [6.1762e-01],\n",
            "        [6.1862e-01],\n",
            "        [6.1962e-01],\n",
            "        [6.2062e-01],\n",
            "        [6.2162e-01],\n",
            "        [6.2262e-01],\n",
            "        [6.2362e-01],\n",
            "        [6.2462e-01],\n",
            "        [6.2563e-01],\n",
            "        [6.2663e-01],\n",
            "        [6.2763e-01],\n",
            "        [6.2863e-01],\n",
            "        [6.2963e-01],\n",
            "        [6.3063e-01],\n",
            "        [6.3163e-01],\n",
            "        [6.3263e-01],\n",
            "        [6.3363e-01],\n",
            "        [6.3463e-01],\n",
            "        [6.3564e-01],\n",
            "        [6.3664e-01],\n",
            "        [6.3764e-01],\n",
            "        [6.3864e-01],\n",
            "        [6.3964e-01],\n",
            "        [6.4064e-01],\n",
            "        [6.4164e-01],\n",
            "        [6.4264e-01],\n",
            "        [6.4364e-01],\n",
            "        [6.4464e-01],\n",
            "        [6.4565e-01],\n",
            "        [6.4665e-01],\n",
            "        [6.4765e-01],\n",
            "        [6.4865e-01],\n",
            "        [6.4965e-01],\n",
            "        [6.5065e-01],\n",
            "        [6.5165e-01],\n",
            "        [6.5265e-01],\n",
            "        [6.5365e-01],\n",
            "        [6.5465e-01],\n",
            "        [6.5566e-01],\n",
            "        [6.5666e-01],\n",
            "        [6.5766e-01],\n",
            "        [6.5866e-01],\n",
            "        [6.5966e-01],\n",
            "        [6.6066e-01],\n",
            "        [6.6166e-01],\n",
            "        [6.6266e-01],\n",
            "        [6.6366e-01],\n",
            "        [6.6466e-01],\n",
            "        [6.6567e-01],\n",
            "        [6.6667e-01],\n",
            "        [6.6767e-01],\n",
            "        [6.6867e-01],\n",
            "        [6.6967e-01],\n",
            "        [6.7067e-01],\n",
            "        [6.7167e-01],\n",
            "        [6.7267e-01],\n",
            "        [6.7367e-01],\n",
            "        [6.7467e-01],\n",
            "        [6.7568e-01],\n",
            "        [6.7668e-01],\n",
            "        [6.7768e-01],\n",
            "        [6.7868e-01],\n",
            "        [6.7968e-01],\n",
            "        [6.8068e-01],\n",
            "        [6.8168e-01],\n",
            "        [6.8268e-01],\n",
            "        [6.8368e-01],\n",
            "        [6.8468e-01],\n",
            "        [6.8569e-01],\n",
            "        [6.8669e-01],\n",
            "        [6.8769e-01],\n",
            "        [6.8869e-01],\n",
            "        [6.8969e-01],\n",
            "        [6.9069e-01],\n",
            "        [6.9169e-01],\n",
            "        [6.9269e-01],\n",
            "        [6.9369e-01],\n",
            "        [6.9469e-01],\n",
            "        [6.9570e-01],\n",
            "        [6.9670e-01],\n",
            "        [6.9770e-01],\n",
            "        [6.9870e-01],\n",
            "        [6.9970e-01],\n",
            "        [7.0070e-01],\n",
            "        [7.0170e-01],\n",
            "        [7.0270e-01],\n",
            "        [7.0370e-01],\n",
            "        [7.0470e-01],\n",
            "        [7.0571e-01],\n",
            "        [7.0671e-01],\n",
            "        [7.0771e-01],\n",
            "        [7.0871e-01],\n",
            "        [7.0971e-01],\n",
            "        [7.1071e-01],\n",
            "        [7.1171e-01],\n",
            "        [7.1271e-01],\n",
            "        [7.1371e-01],\n",
            "        [7.1471e-01],\n",
            "        [7.1572e-01],\n",
            "        [7.1672e-01],\n",
            "        [7.1772e-01],\n",
            "        [7.1872e-01],\n",
            "        [7.1972e-01],\n",
            "        [7.2072e-01],\n",
            "        [7.2172e-01],\n",
            "        [7.2272e-01],\n",
            "        [7.2372e-01],\n",
            "        [7.2472e-01],\n",
            "        [7.2573e-01],\n",
            "        [7.2673e-01],\n",
            "        [7.2773e-01],\n",
            "        [7.2873e-01],\n",
            "        [7.2973e-01],\n",
            "        [7.3073e-01],\n",
            "        [7.3173e-01],\n",
            "        [7.3273e-01],\n",
            "        [7.3373e-01],\n",
            "        [7.3473e-01],\n",
            "        [7.3574e-01],\n",
            "        [7.3674e-01],\n",
            "        [7.3774e-01],\n",
            "        [7.3874e-01],\n",
            "        [7.3974e-01],\n",
            "        [7.4074e-01],\n",
            "        [7.4174e-01],\n",
            "        [7.4274e-01],\n",
            "        [7.4374e-01],\n",
            "        [7.4474e-01],\n",
            "        [7.4575e-01],\n",
            "        [7.4675e-01],\n",
            "        [7.4775e-01],\n",
            "        [7.4875e-01],\n",
            "        [7.4975e-01],\n",
            "        [7.5075e-01],\n",
            "        [7.5175e-01],\n",
            "        [7.5275e-01],\n",
            "        [7.5375e-01],\n",
            "        [7.5475e-01],\n",
            "        [7.5576e-01],\n",
            "        [7.5676e-01],\n",
            "        [7.5776e-01],\n",
            "        [7.5876e-01],\n",
            "        [7.5976e-01],\n",
            "        [7.6076e-01],\n",
            "        [7.6176e-01],\n",
            "        [7.6276e-01],\n",
            "        [7.6376e-01],\n",
            "        [7.6476e-01],\n",
            "        [7.6577e-01],\n",
            "        [7.6677e-01],\n",
            "        [7.6777e-01],\n",
            "        [7.6877e-01],\n",
            "        [7.6977e-01],\n",
            "        [7.7077e-01],\n",
            "        [7.7177e-01],\n",
            "        [7.7277e-01],\n",
            "        [7.7377e-01],\n",
            "        [7.7477e-01],\n",
            "        [7.7578e-01],\n",
            "        [7.7678e-01],\n",
            "        [7.7778e-01],\n",
            "        [7.7878e-01],\n",
            "        [7.7978e-01],\n",
            "        [7.8078e-01],\n",
            "        [7.8178e-01],\n",
            "        [7.8278e-01],\n",
            "        [7.8378e-01],\n",
            "        [7.8478e-01],\n",
            "        [7.8579e-01],\n",
            "        [7.8679e-01],\n",
            "        [7.8779e-01],\n",
            "        [7.8879e-01],\n",
            "        [7.8979e-01],\n",
            "        [7.9079e-01],\n",
            "        [7.9179e-01],\n",
            "        [7.9279e-01],\n",
            "        [7.9379e-01],\n",
            "        [7.9479e-01],\n",
            "        [7.9580e-01],\n",
            "        [7.9680e-01],\n",
            "        [7.9780e-01],\n",
            "        [7.9880e-01],\n",
            "        [7.9980e-01],\n",
            "        [8.0080e-01],\n",
            "        [8.0180e-01],\n",
            "        [8.0280e-01],\n",
            "        [8.0380e-01],\n",
            "        [8.0480e-01],\n",
            "        [8.0581e-01],\n",
            "        [8.0681e-01],\n",
            "        [8.0781e-01],\n",
            "        [8.0881e-01],\n",
            "        [8.0981e-01],\n",
            "        [8.1081e-01],\n",
            "        [8.1181e-01],\n",
            "        [8.1281e-01],\n",
            "        [8.1381e-01],\n",
            "        [8.1481e-01],\n",
            "        [8.1582e-01],\n",
            "        [8.1682e-01],\n",
            "        [8.1782e-01],\n",
            "        [8.1882e-01],\n",
            "        [8.1982e-01],\n",
            "        [8.2082e-01],\n",
            "        [8.2182e-01],\n",
            "        [8.2282e-01],\n",
            "        [8.2382e-01],\n",
            "        [8.2482e-01],\n",
            "        [8.2583e-01],\n",
            "        [8.2683e-01],\n",
            "        [8.2783e-01],\n",
            "        [8.2883e-01],\n",
            "        [8.2983e-01],\n",
            "        [8.3083e-01],\n",
            "        [8.3183e-01],\n",
            "        [8.3283e-01],\n",
            "        [8.3383e-01],\n",
            "        [8.3483e-01],\n",
            "        [8.3584e-01],\n",
            "        [8.3684e-01],\n",
            "        [8.3784e-01],\n",
            "        [8.3884e-01],\n",
            "        [8.3984e-01],\n",
            "        [8.4084e-01],\n",
            "        [8.4184e-01],\n",
            "        [8.4284e-01],\n",
            "        [8.4384e-01],\n",
            "        [8.4484e-01],\n",
            "        [8.4585e-01],\n",
            "        [8.4685e-01],\n",
            "        [8.4785e-01],\n",
            "        [8.4885e-01],\n",
            "        [8.4985e-01],\n",
            "        [8.5085e-01],\n",
            "        [8.5185e-01],\n",
            "        [8.5285e-01],\n",
            "        [8.5385e-01],\n",
            "        [8.5485e-01],\n",
            "        [8.5586e-01],\n",
            "        [8.5686e-01],\n",
            "        [8.5786e-01],\n",
            "        [8.5886e-01],\n",
            "        [8.5986e-01],\n",
            "        [8.6086e-01],\n",
            "        [8.6186e-01],\n",
            "        [8.6286e-01],\n",
            "        [8.6386e-01],\n",
            "        [8.6486e-01],\n",
            "        [8.6587e-01],\n",
            "        [8.6687e-01],\n",
            "        [8.6787e-01],\n",
            "        [8.6887e-01],\n",
            "        [8.6987e-01],\n",
            "        [8.7087e-01],\n",
            "        [8.7187e-01],\n",
            "        [8.7287e-01],\n",
            "        [8.7387e-01],\n",
            "        [8.7487e-01],\n",
            "        [8.7588e-01],\n",
            "        [8.7688e-01],\n",
            "        [8.7788e-01],\n",
            "        [8.7888e-01],\n",
            "        [8.7988e-01],\n",
            "        [8.8088e-01],\n",
            "        [8.8188e-01],\n",
            "        [8.8288e-01],\n",
            "        [8.8388e-01],\n",
            "        [8.8488e-01],\n",
            "        [8.8589e-01],\n",
            "        [8.8689e-01],\n",
            "        [8.8789e-01],\n",
            "        [8.8889e-01],\n",
            "        [8.8989e-01],\n",
            "        [8.9089e-01],\n",
            "        [8.9189e-01],\n",
            "        [8.9289e-01],\n",
            "        [8.9389e-01],\n",
            "        [8.9489e-01],\n",
            "        [8.9590e-01],\n",
            "        [8.9690e-01],\n",
            "        [8.9790e-01],\n",
            "        [8.9890e-01],\n",
            "        [8.9990e-01],\n",
            "        [9.0090e-01],\n",
            "        [9.0190e-01],\n",
            "        [9.0290e-01],\n",
            "        [9.0390e-01],\n",
            "        [9.0490e-01],\n",
            "        [9.0591e-01],\n",
            "        [9.0691e-01],\n",
            "        [9.0791e-01],\n",
            "        [9.0891e-01],\n",
            "        [9.0991e-01],\n",
            "        [9.1091e-01],\n",
            "        [9.1191e-01],\n",
            "        [9.1291e-01],\n",
            "        [9.1391e-01],\n",
            "        [9.1491e-01],\n",
            "        [9.1592e-01],\n",
            "        [9.1692e-01],\n",
            "        [9.1792e-01],\n",
            "        [9.1892e-01],\n",
            "        [9.1992e-01],\n",
            "        [9.2092e-01],\n",
            "        [9.2192e-01],\n",
            "        [9.2292e-01],\n",
            "        [9.2392e-01],\n",
            "        [9.2492e-01],\n",
            "        [9.2593e-01],\n",
            "        [9.2693e-01],\n",
            "        [9.2793e-01],\n",
            "        [9.2893e-01],\n",
            "        [9.2993e-01],\n",
            "        [9.3093e-01],\n",
            "        [9.3193e-01],\n",
            "        [9.3293e-01],\n",
            "        [9.3393e-01],\n",
            "        [9.3493e-01],\n",
            "        [9.3594e-01],\n",
            "        [9.3694e-01],\n",
            "        [9.3794e-01],\n",
            "        [9.3894e-01],\n",
            "        [9.3994e-01],\n",
            "        [9.4094e-01],\n",
            "        [9.4194e-01],\n",
            "        [9.4294e-01],\n",
            "        [9.4394e-01],\n",
            "        [9.4494e-01],\n",
            "        [9.4595e-01],\n",
            "        [9.4695e-01],\n",
            "        [9.4795e-01],\n",
            "        [9.4895e-01],\n",
            "        [9.4995e-01],\n",
            "        [9.5095e-01],\n",
            "        [9.5195e-01],\n",
            "        [9.5295e-01],\n",
            "        [9.5395e-01],\n",
            "        [9.5495e-01],\n",
            "        [9.5596e-01],\n",
            "        [9.5696e-01],\n",
            "        [9.5796e-01],\n",
            "        [9.5896e-01],\n",
            "        [9.5996e-01],\n",
            "        [9.6096e-01],\n",
            "        [9.6196e-01],\n",
            "        [9.6296e-01],\n",
            "        [9.6396e-01],\n",
            "        [9.6496e-01],\n",
            "        [9.6597e-01],\n",
            "        [9.6697e-01],\n",
            "        [9.6797e-01],\n",
            "        [9.6897e-01],\n",
            "        [9.6997e-01],\n",
            "        [9.7097e-01],\n",
            "        [9.7197e-01],\n",
            "        [9.7297e-01],\n",
            "        [9.7397e-01],\n",
            "        [9.7497e-01],\n",
            "        [9.7598e-01],\n",
            "        [9.7698e-01],\n",
            "        [9.7798e-01],\n",
            "        [9.7898e-01],\n",
            "        [9.7998e-01],\n",
            "        [9.8098e-01],\n",
            "        [9.8198e-01],\n",
            "        [9.8298e-01],\n",
            "        [9.8398e-01],\n",
            "        [9.8498e-01],\n",
            "        [9.8599e-01],\n",
            "        [9.8699e-01],\n",
            "        [9.8799e-01],\n",
            "        [9.8899e-01],\n",
            "        [9.8999e-01],\n",
            "        [9.9099e-01],\n",
            "        [9.9199e-01],\n",
            "        [9.9299e-01],\n",
            "        [9.9399e-01],\n",
            "        [9.9499e-01],\n",
            "        [9.9600e-01],\n",
            "        [9.9700e-01],\n",
            "        [9.9800e-01],\n",
            "        [9.9900e-01],\n",
            "        [1.0000e+00]], device='cuda:0', dtype=torch.float64,\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.linspace(domain[0] + eps, domain[1] - eps, n_discretization, dtype=torch.double, device=cuda0).reshape(-1,1)\n",
        "x = Variable(x, requires_grad=True).double()\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "N0jsyeH_VyD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c5371b7-81d4-4a81-c906-226f4bba9d52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19747"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "mlp = nn.Sequential(  \n",
        "  LegendreBlock(n_input, 32),\n",
        "  nn.Linear(32, 64),\n",
        "  nn.Tanh(),\n",
        "  nn.Linear(64, 128),\n",
        "  nn.Tanh(),\n",
        "  nn.Linear(128, 64),\n",
        "  nn.Tanh(),\n",
        "  nn.Linear(64, 16),\n",
        "  nn.Linear(16, n_output)\n",
        ").double()\n",
        "\n",
        "\n",
        "pytorch_total_params = sum(p.numel() for p in mlp.parameters() if p.requires_grad)\n",
        "pytorch_total_params"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MjbANFiiS_h",
        "outputId": "a1fcc875-5d9e-4327-aeb0-daf5baae581b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): LegendreBlock(\n",
              "    (linear): Linear(in_features=1, out_features=1, bias=True)\n",
              "    (tanh): Tanh()\n",
              "    (Legendre): LegendreActivation()\n",
              "  )\n",
              "  (1): Linear(in_features=32, out_features=64, bias=True)\n",
              "  (2): Tanh()\n",
              "  (3): Linear(in_features=64, out_features=128, bias=True)\n",
              "  (4): Tanh()\n",
              "  (5): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (6): Tanh()\n",
              "  (7): Linear(in_features=64, out_features=16, bias=True)\n",
              "  (8): Linear(in_features=16, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "O7fJt8lWVyD3"
      },
      "outputs": [],
      "source": [
        "def get_loss(x, ret_res=False):\n",
        "  y = mlp(x)\n",
        "  y_x = dy_dx(y, x)\n",
        "  y_xx = dy_dx(y_x, x)\n",
        "  y_xxx = dy_dx(y_xx, x)\n",
        "\n",
        "\n",
        "  \"\"\"    \n",
        "  Blasius Eq.: \n",
        "   f''' + 0.5 ff'' = 0\n",
        "   2f''' + ff'' = 0   ,   f(0) = f'(0) = 0, f'(∞) = 1\n",
        "  \"\"\"\n",
        "  \n",
        "  residual = (2 * y_xxx) + (y_xx * y)\n",
        "\n",
        "\n",
        "  # boundaries same for all equations\n",
        "  boundary1 = y[0]\n",
        "  boundary2 = y_x[0]\n",
        "  boundary3 = y_x[-1] - 1\n",
        "\n",
        "  loss = (residual**2).mean() + boundary1**2 + boundary2**2 + boundary3**2\n",
        "  return (loss, residual) if ret_res else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2H9IZlCQVyD4"
      },
      "outputs": [],
      "source": [
        "def closure():\n",
        "  loss = get_loss(x)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9bOqRqaiVyD5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ce0c75-5a3c-4aca-bee2-e3a742dd6120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 000 loss = 00000.0000259118\n",
            "Step: 002 loss = 00055.9813210930\n",
            "Step: 004 loss = 00004.2331779141\n",
            "Step: 006 loss = 00002.6394862677\n",
            "Step: 008 loss = 00001.1261426759\n",
            "Step: 010 loss = 00002.0153609354\n",
            "Step: 012 loss = 00001.6004538459\n",
            "Step: 014 loss = 00001.0001981281\n",
            "Step: 016 loss = 00001.3124108169\n",
            "Step: 018 loss = 00001.3887521732\n",
            "Step: 020 loss = 00001.0714704606\n",
            "Step: 022 loss = 00001.0373027992\n",
            "Step: 024 loss = 00001.1824445381\n",
            "Step: 026 loss = 00001.1051660574\n",
            "Step: 028 loss = 00000.9901707526\n",
            "Step: 030 loss = 00001.0308831079\n",
            "Step: 032 loss = 00001.0467232540\n",
            "Step: 034 loss = 00000.9663918486\n",
            "Step: 036 loss = 00000.9613893124\n",
            "Step: 038 loss = 00000.9608777758\n",
            "Step: 040 loss = 00000.9079678382\n",
            "Step: 042 loss = 00000.9054134658\n",
            "Step: 044 loss = 00000.9092250277\n",
            "Step: 046 loss = 00000.8967732128\n",
            "Step: 048 loss = 00000.9554889584\n",
            "Step: 050 loss = 00000.9253969717\n",
            "Step: 052 loss = 00000.8060863930\n",
            "Step: 054 loss = 00000.8899797971\n",
            "Step: 056 loss = 00000.7796520173\n",
            "Step: 058 loss = 00000.7499136573\n",
            "Step: 060 loss = 00000.5865898359\n",
            "Step: 062 loss = 00000.6214148484\n",
            "Step: 064 loss = 00000.7811620943\n",
            "Step: 066 loss = 00001.1358734785\n",
            "Step: 068 loss = 00000.9857901379\n",
            "Step: 070 loss = 00001.0061575036\n",
            "Step: 072 loss = 00001.0118300763\n",
            "Step: 074 loss = 00001.0003172367\n",
            "Step: 076 loss = 00001.0044659732\n",
            "Step: 078 loss = 00001.0210481925\n",
            "Step: 080 loss = 00000.9976493826\n",
            "Step: 082 loss = 00000.9995278503\n",
            "Step: 084 loss = 00001.0021512951\n",
            "Step: 086 loss = 00001.0003163632\n",
            "Step: 088 loss = 00000.9999040393\n",
            "Step: 090 loss = 00001.0007309841\n",
            "Step: 092 loss = 00000.9997264471\n",
            "Step: 094 loss = 00000.9991345515\n",
            "Step: 096 loss = 00000.9918564251\n",
            "Step: 098 loss = 00000.9863562490\n",
            "Step: 100 loss = 00000.9798316996\n",
            "Step: 102 loss = 00000.8665876156\n",
            "Step: 104 loss = 00000.7479187235\n",
            "Step: 106 loss = 00000.5655574792\n",
            "Step: 108 loss = 00000.2851446413\n",
            "Step: 110 loss = 00000.1305854991\n",
            "Step: 112 loss = 00000.0619420889\n",
            "Step: 114 loss = 00000.0306604511\n",
            "Step: 116 loss = 00000.0158279069\n",
            "Step: 118 loss = 00000.0085704400\n",
            "Step: 120 loss = 00000.0049118277\n",
            "Step: 122 loss = 00000.0028959014\n",
            "Step: 124 loss = 00000.0017239678\n",
            "Step: 126 loss = 00000.0010375878\n",
            "Step: 128 loss = 00000.0006451964\n",
            "Step: 130 loss = 00000.0004127636\n",
            "Step: 132 loss = 00000.0002716404\n",
            "Step: 134 loss = 00000.0001879319\n",
            "Step: 136 loss = 00000.0001382916\n",
            "Step: 138 loss = 00000.0001091727\n",
            "Step: 140 loss = 00000.0000901948\n",
            "Step: 142 loss = 00000.0000754459\n",
            "Step: 144 loss = 00000.0000608907\n",
            "Step: 146 loss = 00000.0000391742\n",
            "Step: 148 loss = 00000.0000233403\n",
            "Step: 150 loss = 00000.0000140132\n",
            "Step: 152 loss = 00000.0000086476\n",
            "Step: 154 loss = 00000.0000054340\n",
            "Step: 156 loss = 00000.0000036259\n",
            "Step: 158 loss = 00000.0000025721\n",
            "Step: 160 loss = 00000.0000019479\n",
            "Step: 162 loss = 00000.0000015881\n",
            "Step: 164 loss = 00000.0000014319\n",
            "Step: 166 loss = 00000.0000013668\n",
            "Step: 168 loss = 00000.0000013542\n",
            "Step: 170 loss = 00000.0000013522\n",
            "Step: 172 loss = 00000.0000013503\n",
            "Step: 174 loss = 00000.0000013485\n",
            "Step: 176 loss = 00000.0000013467\n",
            "Step: 178 loss = 00000.0000013449\n",
            "Step: 180 loss = 00000.0000013431\n",
            "Step: 182 loss = 00000.0000013414\n",
            "Step: 184 loss = 00000.0000013397\n",
            "Step: 186 loss = 00000.0000013381\n",
            "Step: 188 loss = 00000.0000013365\n",
            "Step: 190 loss = 00000.0000013349\n",
            "Step: 192 loss = 00000.0000013333\n",
            "Step: 194 loss = 00000.0000013318\n",
            "Step: 196 loss = 00000.0000013302\n",
            "Step: 198 loss = 00000.0000013287\n",
            "Step: 200 loss = 00000.0000013273\n",
            "Step: 202 loss = 00000.0000013258\n",
            "Step: 204 loss = 00000.0000013244\n",
            "Step: 206 loss = 00000.0000013230\n",
            "Step: 208 loss = 00000.0000013216\n",
            "Step: 210 loss = 00000.0000013202\n",
            "Step: 212 loss = 00000.0000013189\n",
            "Step: 214 loss = 00000.0000013176\n",
            "Step: 216 loss = 00000.0000013163\n",
            "Step: 218 loss = 00000.0000013150\n",
            "Step: 220 loss = 00000.0000013137\n",
            "Step: 222 loss = 00000.0000013124\n",
            "Step: 224 loss = 00000.0000013112\n",
            "Step: 226 loss = 00000.0000013100\n",
            "Step: 228 loss = 00000.0000013088\n",
            "Step: 230 loss = 00000.0000013076\n",
            "Step: 232 loss = 00000.0000013064\n",
            "Step: 234 loss = 00000.0000013052\n",
            "Step: 236 loss = 00000.0000013041\n",
            "Step: 238 loss = 00000.0000013029\n",
            "Step: 240 loss = 00000.0000013018\n",
            "Step: 242 loss = 00000.0000013007\n",
            "Step: 244 loss = 00000.0000012996\n",
            "Step: 246 loss = 00000.0000012985\n",
            "Step: 248 loss = 00000.0000012975\n",
            "Step: 250 loss = 00000.0000012964\n",
            "Step: 252 loss = 00000.0000012954\n",
            "Step: 254 loss = 00000.0000012943\n",
            "Step: 256 loss = 00000.0000012933\n",
            "Step: 258 loss = 00000.0000012923\n",
            "Step: 260 loss = 00000.0000012913\n",
            "Step: 262 loss = 00000.0000012903\n",
            "Step: 264 loss = 00000.0000012894\n",
            "Step: 266 loss = 00000.0000012884\n",
            "Step: 268 loss = 00000.0000012875\n",
            "Step: 270 loss = 00000.0000012865\n",
            "Step: 272 loss = 00000.0000012856\n",
            "Step: 274 loss = 00000.0000012847\n",
            "Step: 276 loss = 00000.0000012837\n",
            "Step: 278 loss = 00000.0000012828\n",
            "Step: 280 loss = 00000.0000012820\n",
            "Step: 282 loss = 00000.0000012811\n",
            "Step: 284 loss = 00000.0000012802\n",
            "Step: 286 loss = 00000.0000012793\n",
            "Step: 288 loss = 00000.0000012785\n",
            "Step: 290 loss = 00000.0000012776\n",
            "Step: 292 loss = 00000.0000012768\n",
            "Step: 294 loss = 00000.0000012760\n",
            "Step: 296 loss = 00000.0000012752\n",
            "Step: 298 loss = 00000.0000012743\n",
            "Step: 300 loss = 00000.0000012735\n",
            "Step: 302 loss = 00000.0000012727\n",
            "Step: 304 loss = 00000.0000012720\n",
            "Step: 306 loss = 00000.0000012712\n",
            "Step: 308 loss = 00000.0000012704\n",
            "Step: 310 loss = 00000.0000012696\n",
            "Step: 312 loss = 00000.0000012689\n",
            "Step: 314 loss = 00000.0000012681\n",
            "Step: 316 loss = 00000.0000012674\n",
            "Step: 318 loss = 00000.0000012667\n",
            "Step: 320 loss = 00000.0000012659\n",
            "Step: 322 loss = 00000.0000012652\n",
            "Step: 324 loss = 00000.0000012645\n",
            "Step: 326 loss = 00000.0000012638\n",
            "Step: 328 loss = 00000.0000012631\n",
            "Step: 330 loss = 00000.0000012624\n",
            "Step: 332 loss = 00000.0000012617\n",
            "Step: 334 loss = 00000.0000012610\n",
            "Step: 336 loss = 00000.0000012603\n",
            "Step: 338 loss = 00000.0000012597\n",
            "Step: 340 loss = 00000.0000012590\n",
            "Step: 342 loss = 00000.0000012584\n",
            "Step: 344 loss = 00000.0000012577\n",
            "Step: 346 loss = 00000.0000012571\n",
            "Step: 348 loss = 00000.0000012564\n",
            "Step: 350 loss = 00000.0000012558\n",
            "Step: 352 loss = 00000.0000012552\n",
            "Step: 354 loss = 00000.0000012545\n",
            "Step: 356 loss = 00000.0000012539\n",
            "Step: 358 loss = 00000.0000012533\n",
            "Step: 360 loss = 00000.0000012527\n",
            "Step: 362 loss = 00000.0000012521\n",
            "Step: 364 loss = 00000.0000012515\n",
            "Step: 366 loss = 00000.0000012509\n",
            "Step: 368 loss = 00000.0000012504\n",
            "Step: 370 loss = 00000.0000012498\n",
            "Step: 372 loss = 00000.0000012492\n",
            "Step: 374 loss = 00000.0000012486\n",
            "Step: 376 loss = 00000.0000012481\n",
            "Step: 378 loss = 00000.0000012475\n",
            "Step: 380 loss = 00000.0000012469\n",
            "Step: 382 loss = 00000.0000012464\n",
            "Step: 384 loss = 00000.0000012459\n",
            "Step: 386 loss = 00000.0000012453\n",
            "Step: 388 loss = 00000.0000012448\n",
            "Step: 390 loss = 00000.0000012442\n",
            "Step: 392 loss = 00000.0000012437\n",
            "Step: 394 loss = 00000.0000012432\n",
            "Step: 396 loss = 00000.0000012427\n",
            "Step: 398 loss = 00000.0000012422\n",
            "Step: 400 loss = 00000.0000012416\n",
            "Step: 402 loss = 00000.0000012411\n",
            "Step: 404 loss = 00000.0000012406\n",
            "Step: 406 loss = 00000.0000012401\n",
            "Step: 408 loss = 00000.0000012396\n",
            "Step: 410 loss = 00000.0000012392\n",
            "Step: 412 loss = 00000.0000012387\n",
            "Step: 414 loss = 00000.0000012382\n",
            "Step: 416 loss = 00000.0000012377\n",
            "Step: 418 loss = 00000.0000012372\n",
            "Step: 420 loss = 00000.0000012368\n",
            "Step: 422 loss = 00000.0000012363\n",
            "Step: 424 loss = 00000.0000012358\n",
            "Step: 426 loss = 00000.0000012354\n",
            "Step: 428 loss = 00000.0000012349\n",
            "Step: 430 loss = 00000.0000012345\n",
            "Step: 432 loss = 00000.0000012340\n",
            "Step: 434 loss = 00000.0000012336\n",
            "Step: 436 loss = 00000.0000012331\n",
            "Step: 438 loss = 00000.0000012327\n",
            "Step: 440 loss = 00000.0000012322\n",
            "Step: 442 loss = 00000.0000012318\n",
            "Step: 444 loss = 00000.0000012314\n",
            "Step: 446 loss = 00000.0000012309\n",
            "Step: 448 loss = 00000.0000012305\n",
            "Step: 450 loss = 00000.0000012301\n",
            "Step: 452 loss = 00000.0000012297\n",
            "Step: 454 loss = 00000.0000012293\n",
            "Step: 456 loss = 00000.0000012289\n",
            "Step: 458 loss = 00000.0000012284\n",
            "Step: 460 loss = 00000.0000012280\n",
            "Step: 462 loss = 00000.0000012276\n",
            "Step: 464 loss = 00000.0000012272\n",
            "Step: 466 loss = 00000.0000012268\n",
            "Step: 468 loss = 00000.0000012264\n",
            "Step: 470 loss = 00000.0000012261\n",
            "Step: 472 loss = 00000.0000012257\n",
            "Step: 474 loss = 00000.0000012253\n",
            "Step: 476 loss = 00000.0000012249\n",
            "Step: 478 loss = 00000.0000012245\n",
            "Step: 480 loss = 00000.0000012241\n",
            "Step: 482 loss = 00000.0000012238\n",
            "Step: 484 loss = 00000.0000012234\n",
            "Step: 486 loss = 00000.0000012230\n",
            "Step: 488 loss = 00000.0000012227\n",
            "Step: 490 loss = 00000.0000012223\n",
            "Step: 492 loss = 00000.0000012219\n",
            "Step: 494 loss = 00000.0000012216\n",
            "Step: 496 loss = 00000.0000012212\n",
            "Step: 498 loss = 00000.0000012209\n",
            "Step: 500 loss = 00000.0000012205\n",
            "Step: 502 loss = 00000.0000012202\n",
            "Step: 504 loss = 00000.0000012198\n",
            "Step: 506 loss = 00000.0000012195\n",
            "Step: 508 loss = 00000.0000012191\n",
            "Step: 510 loss = 00000.0000012188\n",
            "Step: 512 loss = 00000.0000012184\n",
            "Step: 514 loss = 00000.0000012181\n",
            "Step: 516 loss = 00000.0000012178\n",
            "Step: 518 loss = 00000.0000012174\n",
            "Step: 520 loss = 00000.0000012171\n",
            "Step: 522 loss = 00000.0000012168\n",
            "Step: 524 loss = 00000.0000012165\n",
            "Step: 526 loss = 00000.0000012161\n",
            "Step: 528 loss = 00000.0000012158\n",
            "Step: 530 loss = 00000.0000012155\n",
            "Step: 532 loss = 00000.0000012152\n",
            "Step: 534 loss = 00000.0000012149\n",
            "Step: 536 loss = 00000.0000012146\n",
            "Step: 538 loss = 00000.0000012142\n",
            "Step: 540 loss = 00000.0000012139\n",
            "Step: 542 loss = 00000.0000012136\n",
            "Step: 544 loss = 00000.0000012133\n",
            "Step: 546 loss = 00000.0000012130\n",
            "Step: 548 loss = 00000.0000012127\n",
            "Step: 550 loss = 00000.0000012124\n",
            "Step: 552 loss = 00000.0000012121\n",
            "Step: 554 loss = 00000.0000012118\n",
            "Step: 556 loss = 00000.0000012115\n",
            "Step: 558 loss = 00000.0000012112\n",
            "Step: 560 loss = 00000.0000012110\n",
            "Step: 562 loss = 00000.0000012107\n",
            "Step: 564 loss = 00000.0000012104\n",
            "Step: 566 loss = 00000.0000012101\n",
            "Step: 568 loss = 00000.0000012098\n",
            "Step: 570 loss = 00000.0000012095\n",
            "Step: 572 loss = 00000.0000012093\n",
            "Step: 574 loss = 00000.0000012090\n",
            "Step: 576 loss = 00000.0000012087\n",
            "Step: 578 loss = 00000.0000012084\n",
            "Step: 580 loss = 00000.0000012082\n",
            "Step: 582 loss = 00000.0000012079\n",
            "Step: 584 loss = 00000.0000012076\n",
            "Step: 586 loss = 00000.0000012073\n",
            "Step: 588 loss = 00000.0000012071\n",
            "Step: 590 loss = 00000.0000012068\n",
            "Step: 592 loss = 00000.0000012065\n",
            "Step: 594 loss = 00000.0000012063\n",
            "Step: 596 loss = 00000.0000012060\n",
            "Step: 598 loss = 00000.0000012058\n",
            "Step: 600 loss = 00000.0000012055\n",
            "Step: 602 loss = 00000.0000012053\n",
            "Step: 604 loss = 00000.0000012050\n",
            "Step: 606 loss = 00000.0000012048\n",
            "Step: 608 loss = 00000.0000012045\n",
            "Step: 610 loss = 00000.0000012043\n",
            "Step: 612 loss = 00000.0000012040\n",
            "Step: 614 loss = 00000.0000012038\n",
            "Step: 616 loss = 00000.0000012035\n",
            "Step: 618 loss = 00000.0000012033\n",
            "Step: 620 loss = 00000.0000012030\n",
            "Step: 622 loss = 00000.0000012028\n",
            "Step: 624 loss = 00000.0000012025\n",
            "Step: 626 loss = 00000.0000012023\n",
            "Step: 628 loss = 00000.0000012021\n",
            "Step: 630 loss = 00000.0000012018\n",
            "Step: 632 loss = 00000.0000012016\n",
            "Step: 634 loss = 00000.0000012014\n",
            "Step: 636 loss = 00000.0000012011\n",
            "Step: 638 loss = 00000.0000012009\n",
            "Step: 640 loss = 00000.0000012007\n",
            "Step: 642 loss = 00000.0000012004\n",
            "Step: 644 loss = 00000.0000012002\n",
            "Step: 646 loss = 00000.0000012000\n",
            "Step: 648 loss = 00000.0000011998\n",
            "Step: 650 loss = 00000.0000011995\n",
            "Step: 652 loss = 00000.0000011993\n",
            "Step: 654 loss = 00000.0000011991\n",
            "Step: 656 loss = 00000.0000011989\n",
            "Step: 658 loss = 00000.0000011987\n",
            "Step: 660 loss = 00000.0000011985\n",
            "Step: 662 loss = 00000.0000011982\n",
            "Step: 664 loss = 00000.0000011980\n",
            "Step: 666 loss = 00000.0000011978\n",
            "Step: 668 loss = 00000.0000011976\n",
            "Step: 670 loss = 00000.0000011974\n",
            "Step: 672 loss = 00000.0000011972\n",
            "Step: 674 loss = 00000.0000011970\n",
            "Step: 676 loss = 00000.0000011968\n",
            "Step: 678 loss = 00000.0000011966\n",
            "Step: 680 loss = 00000.0000011963\n",
            "Step: 682 loss = 00000.0000011961\n",
            "Step: 684 loss = 00000.0000011959\n",
            "Step: 686 loss = 00000.0000011957\n",
            "Step: 688 loss = 00000.0000011955\n",
            "Step: 690 loss = 00000.0000011953\n",
            "Step: 692 loss = 00000.0000011951\n",
            "Step: 694 loss = 00000.0000011949\n",
            "Step: 696 loss = 00000.0000011947\n",
            "Step: 698 loss = 00000.0000011945\n",
            "Step: 700 loss = 00000.0000011943\n",
            "Step: 702 loss = 00000.0000011942\n",
            "Step: 704 loss = 00000.0000011940\n",
            "Step: 706 loss = 00000.0000011938\n",
            "Step: 708 loss = 00000.0000011936\n",
            "Step: 710 loss = 00000.0000011934\n",
            "Step: 712 loss = 00000.0000011932\n",
            "Step: 714 loss = 00000.0000011930\n",
            "Step: 716 loss = 00000.0000011928\n",
            "Step: 718 loss = 00000.0000011926\n",
            "Step: 720 loss = 00000.0000011925\n",
            "Step: 722 loss = 00000.0000011923\n",
            "Step: 724 loss = 00000.0000011921\n",
            "Step: 726 loss = 00000.0000011919\n",
            "Step: 728 loss = 00000.0000011917\n",
            "Step: 730 loss = 00000.0000011915\n",
            "Step: 732 loss = 00000.0000011914\n",
            "Step: 734 loss = 00000.0000011912\n",
            "Step: 736 loss = 00000.0000011910\n",
            "Step: 738 loss = 00000.0000011908\n",
            "Step: 740 loss = 00000.0000011906\n",
            "Step: 742 loss = 00000.0000011905\n",
            "Step: 744 loss = 00000.0000011903\n",
            "Step: 746 loss = 00000.0000011901\n",
            "Step: 748 loss = 00000.0000011899\n",
            "Step: 750 loss = 00000.0000011898\n",
            "Step: 752 loss = 00000.0000011896\n",
            "Step: 754 loss = 00000.0000011894\n",
            "Step: 756 loss = 00000.0000011893\n",
            "Step: 758 loss = 00000.0000011891\n",
            "Step: 760 loss = 00000.0000011889\n",
            "Step: 762 loss = 00000.0000011888\n",
            "Step: 764 loss = 00000.0000011886\n",
            "Step: 766 loss = 00000.0000011884\n",
            "Step: 768 loss = 00000.0000011883\n",
            "Step: 770 loss = 00000.0000011881\n",
            "Step: 772 loss = 00000.0000011879\n",
            "Step: 774 loss = 00000.0000011878\n",
            "Step: 776 loss = 00000.0000011876\n",
            "Step: 778 loss = 00000.0000011874\n",
            "Step: 780 loss = 00000.0000011873\n",
            "Step: 782 loss = 00000.0000011871\n",
            "Step: 784 loss = 00000.0000011870\n",
            "Step: 786 loss = 00000.0000011868\n",
            "Step: 788 loss = 00000.0000011867\n",
            "Step: 790 loss = 00000.0000011865\n",
            "Step: 792 loss = 00000.0000011863\n",
            "Step: 794 loss = 00000.0000011862\n",
            "Step: 796 loss = 00000.0000011860\n",
            "Step: 798 loss = 00000.0000011859\n",
            "Step: 800 loss = 00000.0000011857\n",
            "Step: 802 loss = 00000.0000011856\n",
            "Step: 804 loss = 00000.0000011854\n",
            "Step: 806 loss = 00000.0000011853\n",
            "Step: 808 loss = 00000.0000011851\n",
            "Step: 810 loss = 00000.0000011850\n",
            "Step: 812 loss = 00000.0000011848\n",
            "Step: 814 loss = 00000.0000011847\n",
            "Step: 816 loss = 00000.0000011845\n",
            "Step: 818 loss = 00000.0000011844\n",
            "Step: 820 loss = 00000.0000011842\n",
            "Step: 822 loss = 00000.0000011841\n",
            "Step: 824 loss = 00000.0000011839\n",
            "Step: 826 loss = 00000.0000011838\n",
            "Step: 828 loss = 00000.0000011836\n",
            "Step: 830 loss = 00000.0000011835\n",
            "Step: 832 loss = 00000.0000011834\n",
            "Step: 834 loss = 00000.0000011832\n",
            "Step: 836 loss = 00000.0000011831\n",
            "Step: 838 loss = 00000.0000011829\n",
            "Step: 840 loss = 00000.0000011828\n",
            "Step: 842 loss = 00000.0000011827\n",
            "Step: 844 loss = 00000.0000011825\n",
            "Step: 846 loss = 00000.0000011824\n",
            "Step: 848 loss = 00000.0000011822\n",
            "Step: 850 loss = 00000.0000011821\n",
            "Step: 852 loss = 00000.0000011820\n",
            "Step: 854 loss = 00000.0000011818\n",
            "Step: 856 loss = 00000.0000011817\n",
            "Step: 858 loss = 00000.0000011816\n",
            "Step: 860 loss = 00000.0000011814\n",
            "Step: 862 loss = 00000.0000011813\n",
            "Step: 864 loss = 00000.0000011812\n",
            "Step: 866 loss = 00000.0000011810\n",
            "Step: 868 loss = 00000.0000011809\n",
            "Step: 870 loss = 00000.0000011808\n",
            "Step: 872 loss = 00000.0000011806\n",
            "Step: 874 loss = 00000.0000011805\n",
            "Step: 876 loss = 00000.0000011804\n",
            "Step: 878 loss = 00000.0000011802\n",
            "Step: 880 loss = 00000.0000011801\n",
            "Step: 882 loss = 00000.0000011800\n",
            "Step: 884 loss = 00000.0000011798\n",
            "Step: 886 loss = 00000.0000011797\n",
            "Step: 888 loss = 00000.0000011796\n",
            "Step: 890 loss = 00000.0000011795\n",
            "Step: 892 loss = 00000.0000011793\n",
            "Step: 894 loss = 00000.0000011792\n",
            "Step: 896 loss = 00000.0000011791\n",
            "Step: 898 loss = 00000.0000011790\n",
            "Step: 900 loss = 00000.0000011788\n",
            "Step: 902 loss = 00000.0000011787\n",
            "Step: 904 loss = 00000.0000011786\n",
            "Step: 906 loss = 00000.0000011785\n",
            "Step: 908 loss = 00000.0000011784\n",
            "Step: 910 loss = 00000.0000011782\n",
            "Step: 912 loss = 00000.0000011781\n",
            "Step: 914 loss = 00000.0000011780\n",
            "Step: 916 loss = 00000.0000011779\n",
            "Step: 918 loss = 00000.0000011777\n",
            "Step: 920 loss = 00000.0000011776\n",
            "Step: 922 loss = 00000.0000011775\n",
            "Step: 924 loss = 00000.0000011774\n",
            "Step: 926 loss = 00000.0000011773\n",
            "Step: 928 loss = 00000.0000011772\n",
            "Step: 930 loss = 00000.0000011770\n",
            "Step: 932 loss = 00000.0000011769\n",
            "Step: 934 loss = 00000.0000011768\n",
            "Step: 936 loss = 00000.0000011767\n",
            "Step: 938 loss = 00000.0000011766\n",
            "Step: 940 loss = 00000.0000011765\n",
            "Step: 942 loss = 00000.0000011763\n",
            "Step: 944 loss = 00000.0000011762\n",
            "Step: 946 loss = 00000.0000011761\n",
            "Step: 948 loss = 00000.0000011760\n",
            "Step: 950 loss = 00000.0000011759\n",
            "Step: 952 loss = 00000.0000011758\n",
            "Step: 954 loss = 00000.0000011757\n",
            "Step: 956 loss = 00000.0000011756\n",
            "Step: 958 loss = 00000.0000011755\n",
            "Step: 960 loss = 00000.0000011753\n",
            "Step: 962 loss = 00000.0000011752\n",
            "Step: 964 loss = 00000.0000011751\n",
            "Step: 966 loss = 00000.0000011750\n",
            "Step: 968 loss = 00000.0000011749\n",
            "Step: 970 loss = 00000.0000011748\n",
            "Step: 972 loss = 00000.0000011747\n",
            "Step: 974 loss = 00000.0000011746\n",
            "Step: 976 loss = 00000.0000011745\n",
            "Step: 978 loss = 00000.0000011744\n",
            "Step: 980 loss = 00000.0000011743\n",
            "Step: 982 loss = 00000.0000011742\n",
            "Step: 984 loss = 00000.0000011740\n",
            "Step: 986 loss = 00000.0000011739\n",
            "Step: 988 loss = 00000.0000011738\n",
            "Step: 990 loss = 00000.0000011737\n",
            "Step: 992 loss = 00000.0000011736\n",
            "Step: 994 loss = 00000.0000011735\n",
            "Step: 996 loss = 00000.0000011734\n",
            "Step: 998 loss = 00000.0000011733\n",
            "Step: 1000 loss = 00000.0000011732\n",
            "Step: 1002 loss = 00000.0000011731\n",
            "Step: 1004 loss = 00000.0000011730\n",
            "Step: 1006 loss = 00000.0000011729\n",
            "Step: 1008 loss = 00000.0000011728\n",
            "Step: 1010 loss = 00000.0000011727\n",
            "Step: 1012 loss = 00000.0000011726\n",
            "Step: 1014 loss = 00000.0000011725\n",
            "Step: 1016 loss = 00000.0000011724\n",
            "converged\n",
            "Final loss = 1.17e-06\n"
          ]
        }
      ],
      "source": [
        "#TODO\n",
        "optimizer = optim.Adam(list(mlp.parameters()), lr=0.01, betas=(0.9, 0.999), eps=1e-32)\n",
        "previous = 0\n",
        "losses = []\n",
        "epoch_Adam = 100\n",
        "epoch_LBFGS = 5000\n",
        "for i in range(epoch_Adam):\n",
        "  loss = get_loss(x)\n",
        "  \n",
        "  if i % 2 == 0:        \n",
        "    print('Step: %03d loss = %016.10f' % (i, loss))        \n",
        "  \n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  losses.append(loss.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "optimizer = optim.LBFGS(list(mlp.parameters()), lr = 0.01)\n",
        "previous = 0\n",
        "for i in range(epoch_LBFGS):\n",
        "  loss = get_loss(x)\n",
        "  if i % 2 == 0:        \n",
        "    print('Step: %03d loss = %016.10f' % (i+epoch_Adam, loss))\n",
        "    if abs(previous - loss) < 1e-10:\n",
        "        print('converged')\n",
        "        break\n",
        "    \n",
        "    previous = loss\n",
        "  \n",
        "  losses.append(loss.detach().cpu().numpy())\n",
        "  optimizer.step(closure)\n",
        "\n",
        "print(\"Final loss = %.2e\" % get_loss(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CY9Z8dRKVyD6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "69eeb5f0-84ba-4960-b2d5-1531b0a03397"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   x                   y\n",
              "0 0.0000000000000000 -0.0000027895915439\n",
              "1 0.1000000000000000  0.0051042379946116\n",
              "2 0.2000000000000000  0.0204212138627372\n",
              "3 0.5000000000000000  0.1275088286981601\n",
              "4 1.0000000000000000  0.5062977524877190\n",
              "5 1.5000000000000000  1.1099985865726627\n",
              "6 2.0000000000000000  1.6378331452849346"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67a033fe-e0f4-452c-9b24-c7292fd4b492\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0000000000000000</td>\n",
              "      <td>-0.0000027895915439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1000000000000000</td>\n",
              "      <td>0.0051042379946116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.2000000000000000</td>\n",
              "      <td>0.0204212138627372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.5000000000000000</td>\n",
              "      <td>0.1275088286981601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0000000000000000</td>\n",
              "      <td>0.5062977524877190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.5000000000000000</td>\n",
              "      <td>1.1099985865726627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.0000000000000000</td>\n",
              "      <td>1.6378331452849346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67a033fe-e0f4-452c-9b24-c7292fd4b492')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67a033fe-e0f4-452c-9b24-c7292fd4b492 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67a033fe-e0f4-452c-9b24-c7292fd4b492');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "pd.options.display.float_format = '{:.16f}'.format\n",
        "domain_test = torch.tensor([0.00,0.10,0.20,0.50,1.00,1.50,2.00], dtype=torch.double).reshape(-1,1)\n",
        "predict_test = mlp.cpu().forward(domain_test).detach().numpy().flatten()\n",
        "pd.DataFrame(np.array([domain_test.numpy().flatten(), predict_test]).T, columns=['x','y'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zdmgRC0AVyD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe15c3f1-60dc-4ccc-8e37-7b37f46fbbc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f''(0) = 1.0211181181093765\n"
          ]
        }
      ],
      "source": [
        "# calculate f''(0)\n",
        "# # make zero Tensor from x Tensor\n",
        "zerox = x.cpu().clone()\n",
        "zerox[0][0] = 0\n",
        "f_xx_0 = d2y_dx2(mlp(zerox), zerox)[0]\n",
        "print(\"f''(0) = {}\".format(f_xx_0[0]))\n",
        "\n",
        "# history \n",
        "# f''(0) = 0.3325398571314273 \n",
        "# f''(0) = 0.3321312229973239"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf10PzmNVyD7"
      },
      "outputs": [],
      "source": [
        "#[TODO]\n",
        "domain = x.detach().numpy().flatten()\n",
        "# exact = (1 - x**2 / 6).detach().numpy().flatten()\n",
        "predict = mlp.forward(x).detach().numpy().flatten()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "\n",
        "# plt.plot(domain, exact,'k--', markersize=.1, label='Exact')\n",
        "plt.plot(domain, predict,'b.', markersize=1, label='Predict')\n",
        "plt.legend()\n",
        "\n",
        "# plt.savefig('exact-predict.eps', bbox_inches='tight', format='eps')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i9w6wQuVyD8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "res= get_loss(x, ret_res=True)[1].detach().numpy()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Residual')\n",
        "plt.plot(domain, res)\n",
        "plt.savefig('residual-loss.eps', bbox_inches='tight', format='eps')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4TEZCiWVyD9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(np.log(losses))\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('log(loss)')\n",
        "\n",
        "plt.savefig('loss.eps', bbox_inches='tight', format='eps')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD9P9n85VyD9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "ode_legendre.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}